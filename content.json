{"meta":{"title":"ChaosCoffee' blog","subtitle":null,"description":null,"author":"ChaoCofee","url":"https://chaoscoffee.github.io"},"pages":[{"title":"categories","date":"2018-07-27T06:39:54.000Z","updated":"2018-09-10T10:31:35.600Z","comments":true,"path":"categories/index.html","permalink":"https://chaoscoffee.github.io/categories/index.html","excerpt":"","text":""},{"title":"interview","date":"2018-07-27T06:39:54.000Z","updated":"2018-09-10T10:31:35.600Z","comments":true,"path":"categories/interview/index.html","permalink":"https://chaoscoffee.github.io/categories/interview/index.html","excerpt":"","text":""},{"title":"programmes","date":"2018-07-27T06:39:54.000Z","updated":"2018-09-10T10:31:35.600Z","comments":true,"path":"categories/programmes/index.html","permalink":"https://chaoscoffee.github.io/categories/programmes/index.html","excerpt":"","text":""},{"title":"tools","date":"2018-07-27T06:39:54.000Z","updated":"2018-09-10T10:31:35.600Z","comments":true,"path":"categories/tools/index.html","permalink":"https://chaoscoffee.github.io/categories/tools/index.html","excerpt":"","text":""}],"posts":[{"title":"搭建个人博客教程(三)","slug":"搭建个人博客教程3","date":"2018-09-10T08:56:25.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/09/10/搭建个人博客教程3/","link":"","permalink":"https://chaoscoffee.github.io/2018/09/10/搭建个人博客教程3/","excerpt":"","text":"搭建个人博客教程(三)这一篇是利用GitHub进行托管访问,提交代码自动部署访问,省去每次都要本地搭建一套环境的麻烦事. 搭建个人博客教程(三) 创建仓库 域名配置 访问 持续集成&amp;部署 Travis CI介绍 Travis CI准备工作 编写.travis.yml脚本 查看Travis CI工作 扩展 创建仓库到GitHub上新建一个仓库.点击仓库Settings可以看到相关配置信息.名称必须要使用{username}.github.io格式规范 域名配置这一步,没有域名的同学可以不要.根目录下创建CNAME文件,里面填写域名名称,然后去相应云厂商DNS解析，也有免费的https://www.dnspod.cn/ 访问提交你的代码到master分支,然后访问https://chaoscoffee.github.io/或者域名就能展示和本地一样的界面了. 持续集成&amp;部署Travis CI介绍这里介绍一下进阶的用法,我们编写博客只是为了写一些文章放上面,中间繁琐的配置和搭建环境希望省略而不是每一次换一个机器都要重新搭建一次.这里CI的好处就出来了. Travis CI 提供的是持续集成服务（Continuous Integration，简称 CI）。它绑定 Github 上面的项目，只要有新的代码，就会自动抓取。然后，提供一个运行环境，执行测试，完成构建，部署到服务器。 这里提供了免费版本: https://travis-ci.org/也可以用企业版本,私有的(收费) https://travis-ci.com/ 所以接下来预期目标就是提交代码到GitHub上,然后Travis CI帮我们创建Hexo环境生成，编译之类的.只需要提交一篇博客文章就可以打开浏览器看到效果. Travis CI准备工作https://travis-ci.org/创建账户，这里直接使用GitHub账户登录，这样Travis CI可以拉取到所有的仓库，对你要发布的仓库置为开启状态. 点击setting显示如下: 编写.travis.yml脚本既然想要Travis CI做我们想做的事情，那就需要实现告知它要干啥.这里需要在Github仓库根路径下创建.travis.yml执行脚本.其实这个脚本实现的内容很简单，第一个是监听分支，然后更新运行Hexo环境,然后提交给master分支代码. 创建分支根据以上描述，我们需要建立一个新分支，建立所有分支如下 master hexo 编写脚本创建脚本.travis.yml放到根目录下. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647language: node_js #设置环境node_js: stablesudo: false#cachecache: directories: - \"node_modules\" #缓存目录notifications: email: recipients: - chaos183@163.com #通知邮箱 on_success: change on_failure: always# S: Build Lifecycleinstall: - npm install# - gem install travis# - travis login --pro --github-token $&#123;GH_TOKEN&#125;before_script: #准备工作 - export TZ='Asia/Shanghai' - npm install -g gulp # 这是压缩格式css,js等文件插件，可以不要 - chmod +x _travis.sh # 赋予权限script: #执行脚本 - hexo clean &amp;&amp; hexo g # hexo 生成 - gulp # 执行gulp命令,可以不需要after_success: # - LAST_BUILD_NUMBER=68 # - for i in $(seq 1 $LAST_BUILD_NUMBER ); do travis logs $i --delete --force ; doneafter_script: - ./_travis.sh #执行shell,见下面贴出# E: Build LifeCyclebranches: only: - hexo #只监听这个分支代码env: global: - GH_REF: github.com/ChaosCoffee/ChaosCoffee.github.io.git #全局变量仓库地址 下面就是拉取仓库地址,提交代码的脚本了_travis.sh,也可以把下面的shell搬到上面文件一起。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#!/bin/bash#定义时间time=`date +%Y-%m-%d\\ %H:%M:%S`#执行成功function success()&#123; echo \"success\"&#125;#执行失败function failure()&#123; echo \"failure\"&#125;#默认执行function default()&#123; git clone https://$&#123;GH_REF&#125; .deploy_git cd .deploy_git git checkout master cd ../ mv .deploy_git/.git/ ./public/ cd ./publiccat &lt;&lt;EOF &gt;&gt; build-log.md部署状态 | 集成结果 | 参考值---|---|---完成时间 | $time | yyyy-mm-dd hh:mm:ss部署环境 | $TRAVIS_OS_NAME + $TRAVIS_NODE_VERSION | window \\| linux + stable部署类型 | $TRAVIS_EVENT_TYPE | push \\| pull_request \\| api \\| cron启用Sudo | $TRAVIS_SUDO | false \\| true仓库地址 | $TRAVIS_REPO_SLUG | owner_name/repo_name提交分支 | $TRAVIS_COMMIT | hash 16位提交信息 | $TRAVIS_COMMIT_MESSAGE |Job ID | $TRAVIS_JOB_ID |Job NUM | $TRAVIS_JOB_NUMBER |EOF git init git config user.name \"ChaosCoffee\" git config user.email \"1104855822@qq.com\" git add . git commit -m \"update blog by travis-ci with build version $TRAVIS_BUILD_NUMBER\" # Github Pages git push --force --quiet \"https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;\" master:master # 这里的GH_TOKEN后面会介绍，相当于预置的一个环境变量 # Create Tag #git tag v1.2.$TRAVIS_BUILD_NUMBER -a -m \"Auto Taged By TravisCI With Build $TRAVIS_BUILD_NUMBER\" # Github Pages #git push --quiet \"https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;\" master:master --tags&#125;case $1 in \"success\") success ;; \"failure\") failure ;; *) defaultesac 配置Token和环境变量上面脚本用到了GH_TOKEN这个变量,其实是一个GitHub的权限Token,这个是私有的，不想让其他人看见，否则任何人都能提交到你的仓库里了.首先到GitHub上配置personal access token. 3.1 新建Token 3.2 给Token相应权限 注意：这里生成Token值记得保存下来，不然再重新打开页面就看不到了 3.3 Travis CI环境变量travis ci 仓库setting里配置 GH_TOKEN,这样环境变量配置工作全部都完成了. 参考可以参考我的配置,改动下自己的仓库地址和环境变量,分支就行了..travis.yml_travis.sh 查看Travis CI工作这里可以在控制台看到对面Job运行. Job构建历史记录 扩展很多项目有这个结果反馈图标，可以通过Travis CI提供的Job情况来看到，注意选择hexo分支，否则会看到unknown.","categories":[{"name":"blog","slug":"blog","permalink":"https://chaoscoffee.github.io/categories/blog/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://chaoscoffee.github.io/tags/hexo/"}],"keywords":[{"name":"blog","slug":"blog","permalink":"https://chaoscoffee.github.io/categories/blog/"}]},{"title":"搭建个人博客教程(二)","slug":"搭建个人博客教程2","date":"2018-09-10T06:01:26.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/09/10/搭建个人博客教程2/","link":"","permalink":"https://chaoscoffee.github.io/2018/09/10/搭建个人博客教程2/","excerpt":"","text":"搭建个人博客教程(二) 搭建个人博客教程(二) 更换Hexo主题 下载主题 更改主题 查看 Page使用 新建Page 修改config配置 新建文章 查看Hexo 注 更换Hexo主题默认的主题界面总是得不到青睐, Hexo贴心的提供很多支持，包括主题, 主题列表 这里包括Hexo的所有可用定制主题，可以根据自己喜欢挑选一个.下面用NexT目前最受欢迎的作为搭建示例. 下载主题目前大部分主题仓库托管在GitHub上面，所以很方面的使用下面命令下载到本地，也可以直接下载然后解压到本地，推荐使用第二种方式，以后同步直接使用git pull就行了. NexT download 方式 $ mkdir themes/next$ curl -s https://api.github.com/repos/iissnan/hexo-theme-next/releases/latest | grep tarball_url | cut -d ‘“‘ -f 4 | wget -i - -O- | tar -zx -C themes/next –strip-components=1 git clone方式 git clone https://github.com/iissnan/hexo-theme-next themes/next 更改主题找到根目录文件_config.yml的theme 属性，默认配置是: 1theme: landscape 我们将它改为NexT: 1theme: next 查看本地发布 hexo g &amp;&amp; hexo s –debug打开http://localhost:4000/在浏览器访问. 这样就成功了. Page使用Hexo里的page相当于网页展示的页面，标签，分类都可以通过hexo new page来生成. 新建Page hexo new page &lt;page_name&gt; 新建分类: hexo new page categories 这时候根目录source下会出现categories目录，目录下生成了index.md文件.添加内容 type: type: categories 123title: categoriesdate: 2018-09-10 15:18:53type: categories 修改config配置修改myblog/themes/next主题目录下的_config.yml文件，放开categories注释. 123456789menu: home: / || home #about: /about/ || user #tags: /tags/ || tags #categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 这里其可以猜出作者的意思，需要其他的功能菜单，就放开对应的注释. 新建文章接下来就是写文章的时候了 新建文章 hexo new post &lt;article_name&gt; hexo new post first-article 同样在source\\_posts目录下，有着所有的新建文章，找到刚刚新建的first-article.md.添加categories: tools，这里tools是随便设置的一个分类，可以自己根据文章的类型去自行分类。 1234title: first-articledate: 2018-09-10 15:20:55tags:categories: tools 查看Hexo所有的完成工作准备完成，重新生成访问看到出现了新的分类. 注以上只介绍最常用的分类和文章，更多的命令也用不上，或者喜欢个性化的同学可以去官网看一下. 写作","categories":[{"name":"blog","slug":"blog","permalink":"https://chaoscoffee.github.io/categories/blog/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://chaoscoffee.github.io/tags/hexo/"}],"keywords":[{"name":"blog","slug":"blog","permalink":"https://chaoscoffee.github.io/categories/blog/"}]},{"title":"搭建个人博客教程(一)","slug":"搭建个人博客教程1","date":"2018-09-10T06:01:20.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/09/10/搭建个人博客教程1/","link":"","permalink":"https://chaoscoffee.github.io/2018/09/10/搭建个人博客教程1/","excerpt":"","text":"搭建个人博客教程(一) 搭建个人博客教程(一) Hexo 入门 Hexo安装 必要条件 安装 验证 Hexo建站 初始化 生成和部署 本地预览 参考 Hexo 入门 Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 Hexo安装必要条件 Node.js Git 安装使用 npm 即可完成 Hexo 的安装 $ npm install -g hexo-cli 验证 $ hexo -version 显示以下则说明安装成功. Hexo建站初始化按顺序执行以下命令,生产Hexo资源目录. $ hexo init $ cd $ npm install 注: &lt;folder&gt;是你要创建的文件目录名称，例如:hexo init myblog 自动生成目录如图 生成和部署上述的环境已经搭建好了,下面就是怎么生成和发布了. 生成hexo资源文件 $ hexo generate 部署 $ hexo deploy 也可以简写，以下命令意思是生成完毕并部署: $ hexo g -d 本地预览本地预览使用以下命令: hexo cleanhexo ghexo s 也可以简写: 清除缓存的public目录文件并生成. hexo clean &amp;&amp; hexo g 启动本地服务并以-p 指定端口4000访问，默认端口是4000. --debug好处可以改动后热编译生成不需要关闭重新执行. hexo s -p 4000 –debug 这样可以在 打开浏览器,输入http://localhost:4000/便可以看到自己的博客了. 参考官方文档","categories":[{"name":"blog","slug":"blog","permalink":"https://chaoscoffee.github.io/categories/blog/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://chaoscoffee.github.io/tags/hexo/"}],"keywords":[{"name":"blog","slug":"blog","permalink":"https://chaoscoffee.github.io/categories/blog/"}]},{"title":"如何通过配置根据环境(条件)实例化Bean","slug":"如何根据条件实例化Bean","date":"2018-08-29T07:34:37.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/08/29/如何根据条件实例化Bean/","link":"","permalink":"https://chaoscoffee.github.io/2018/08/29/如何根据条件实例化Bean/","excerpt":"","text":"如何通过配置根据环境(条件)实例化Bean 如何通过配置根据环境(条件)实例化Bean 背景介绍 通过@Profile 实现 @Profile 介绍 @Profile应用 通过@ConditionalOnProperty 实现 @ConditionalOnProperty介绍 @ConditionalOnProperty应用 通过工厂模式实现 场景介绍 应用实现 场景比较 背景介绍如果需要不同的服务加载不同的配置,例如数据库配置，MongoDB或者MySQL等，启动的时候需要根据不同的条件来决定加载哪一个就可以，而不必要全部加载. 通过@Profile 实现@Profile 介绍@Profile注解可以联合SpringBoot可以根据配置文件里application.yml 里的属性 spring.profiles.active=xxx 配置来实现,需要添加额外的profile文件。规范来说，@Profile一般都是作为不同的环境来区分，比如开发，测试，生产环境来做区分，不适合单个环境作为具体配置。 下面是官方完整的API: 123456789101112@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Conditional(ProfileCondition.class)public @interface Profile &#123; /** * The set of profiles for which the annotated component should be registered. */ String[] value();&#125; @Profile应用 首先定义接口DatabaseOperationService 12345public interface DatabaseOperationService &#123; List listByPage();&#125; 需要作为不同的数据库方式则实现此接口(具体实现代码忽略) JDBC实现类:12345678910public class JDBCServiceImpl implements DatabaseOperationService &#123; @Autowired private JdbcTemplate jdbcTemplate; @Override public List listByPage() &#123; return Lists.newArrayList(); &#125;&#125; Mongo实现类:12345678910111213public class MongoServiceImpl implements DatabaseOperationService &#123; private MongoTemplate mongoTemplate; public MongoServiceImpl(final MongoTemplate mongoTemplate) &#123; this.mongoTemplate = mongoTemplate; &#125; @Override public List listByPage() &#123; return Lists.newArrayList(); &#125;&#125; 根据配置来实例需要的数据库加载方式配置类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889@Configurationpublic class DataBaseConfiguration &#123; /** * spring.profiles.active = &#123;&#125;. */ @Configuration @Profile(\"db\") static class JdbcConfiguration &#123; private final Environment env; @Autowired JdbcConfiguration(final Environment env) &#123; this.env = env; &#125; @Bean public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(env.getProperty(\"db.driver\")); dataSource.setUrl(env.getProperty(\"db.url\")); //用户名 dataSource.setUsername(env.getProperty(\"db.username\")); //密码 dataSource.setPassword(env.getProperty(\"db.password\")); dataSource.setInitialSize(2); dataSource.setMaxActive(20); dataSource.setMinIdle(0); dataSource.setMaxWait(60000); dataSource.setValidationQuery(\"SELECT 1\"); dataSource.setTestOnBorrow(false); dataSource.setTestWhileIdle(true); dataSource.setPoolPreparedStatements(false); return dataSource; &#125; @Bean @Qualifier(\"jdbcService\") public DatabaseOperationService jdbcService() &#123; JDBCServiceImpl jdbcService = new JDBCServiceImpl(); return jdbcService; &#125; &#125; @Configuration @Profile(\"mongo\") static class MongoConfiguration &#123; private final Environment env; @Autowired MongoConfiguration(final Environment env) &#123; this.env = env; &#125; @Bean @Qualifier(\"DatabaseOperationService\") public DatabaseOperationService mongoService() &#123; MongoClientFactoryBean clientFactoryBean = new MongoClientFactoryBean(); MongoCredential credential = MongoCredential.createScramSha1Credential( env.getProperty(\"mongo.userName\"), env.getProperty(\"mongo.dbName\"), env.getProperty(\"mongo.password\").toCharArray()); clientFactoryBean.setCredentials(new MongoCredential[]&#123;credential&#125;); List&lt;String&gt; urls = Splitter.on(\",\").trimResults().splitToList(env.getProperty(\"mongo.url\")); ServerAddress[] sds = new ServerAddress[urls.size()]; for (int i = 0; i &lt; sds.length; i++) &#123; List&lt;String&gt; adds = Splitter.on(\":\").trimResults().splitToList(urls.get(i)); InetSocketAddress address = new InetSocketAddress(adds.get(0), Integer.parseInt(adds.get(1))); sds[i] = new ServerAddress(address); &#125; clientFactoryBean.setReplicaSetSeeds(sds); MongoTemplate mongoTemplate = null; try &#123; clientFactoryBean.afterPropertiesSet(); mongoTemplate = new MongoTemplate(clientFactoryBean.getObject(), env.getProperty(\"mongo.dbName\")); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return new MongoServiceImpl(mongoTemplate); &#125; &#125;&#125; 配置文件resource目录下存在 applicaiton-db.yml或者 applicaiton-mongo.yml就能找到对应属性配置，同时在application.yml父级配置文件指定有效配置环境。 通过@ConditionalOnProperty 实现@ConditionalOnProperty介绍这种方式与上面一种比较起来，更为灵活,@Profile更多用于环境级别，@ConditionalOnProperty则可以控制@Configuration是否生效，根据配置文件的不用来实现不同的加载bean. value 获取对应property名称的值，与name不可同时使用 prefix property名称的前缀，可有可无 name property完整名称或部分名称（可与prefix组合使用，组成完整的property名称），与value不可同时使用 havingValue 可与name组合使用，比较获取到的属性值与havingValue给定的值是否相同，相同才加载配置 matchIfMissing 缺少该property时是否可以加载。如果为true，没有该property也会正常加载;反之报错 relaxedNames 松散匹配，可以理解为多变量的变种 下面是官方完整的API 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Retention(RetentionPolicy.RUNTIME)@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)@Documented@Conditional(OnPropertyCondition.class)public @interface ConditionalOnProperty &#123; /** * Alias for &#123;@link #name()&#125;. * @return the names */ String[] value() default &#123;&#125;; /** * A prefix that should be applied to each property. The prefix automatically ends * with a dot if not specified. * @return the prefix */ String prefix() default \"\"; /** * The name of the properties to test. If a prefix has been defined, it is applied to * compute the full key of each property. For instance if the prefix is * &#123;@code app.config&#125; and one value is &#123;@code my-value&#125;, the fully key would be * &#123;@code app.config.my-value&#125; * &lt;p&gt; * Use the dashed notation to specify each property, that is all lower case with a \"-\" * to separate words (e.g. &#123;@code my-long-property&#125;). * @return the names */ String[] name() default &#123;&#125;; /** * The string representation of the expected value for the properties. If not * specified, the property must &lt;strong&gt;not&lt;/strong&gt; be equals to &#123;@code false&#125;. * @return the expected value */ String havingValue() default \"\"; /** * Specify if the condition should match if the property is not set. Defaults to * &#123;@code false&#125;. * @return if should match if the property is missing */ boolean matchIfMissing() default false; /** * If relaxed names should be checked. Defaults to &#123;@code true&#125;. * @return if relaxed names are used */ boolean relaxedNames() default true;&#125; @ConditionalOnProperty应用 添加注解@ConditionalOnProperty为了方便，仍然使用以上代码，只需要将这部分代码替换为下面的： 12345678修改前: @Profile(\"db\")...修改后:@ConditionalOnProperty(value = &#123;\"database.spi\"&#125;,havingValue = \"db\")... 添加配置在application.yml里指定database.spi=xxx 通过工厂模式实现以上的两种方式都可以实现我们的切换服务的需求，但是不通过直接注解，代码实现也能实现,下面让我们试试吧. 场景介绍一般说来，有调用不同的厂商发送短信，例如联通，移动，电信这些不同的运营商，可能还会中间经过不同的代理商，这个就不细谈了。还有使用不同的文件服务器上传服务，例如阿里的oss，亚马逊的aws之类的。还有金融不同的支付接口，阿里，中金，连连之类的。原来只在一个的基础上没有问题，按照流程到哪步进行开发，这样以后需要切换一个服务就得加很多不同的调用代码。所以针对这个情况，我们希望可以有个公共部分替我们管理，而我们只需要写好各自的真正调用部分的代码就行了。这时候工厂模式就派上用场了，预先在生产好产品或者服务，调用方只需要根据自己的需要去拿就可以了。 应用实现 定义数据库枚举类 123456789101112131415161718192021public enum DatabaseEnum &#123; MYSQL(\"msql\"), MONGONDB(\"mongoDb\"), UNACCEPT(\"unaccept\"); @Getter private String name; DatabaseEnum(String name) &#123; this.name = name; &#125; public static DatabaseEnum getAcceptApplicationNameEnum(String name) &#123; for (DatabaseEnum databaseEnum : DatabaseEnum.values()) &#123; if (databaseEnum.name.equals(name)) &#123; return databaseEnum; &#125; &#125; return UNACCEPT; &#125;&#125; 增加接口方法这里其实是为了下面工厂类更好的找到Bean,或者不用接口增加方法，给实例Bean设置别名和配置文件保持一致即可。 123456public interface DatabaseOperationService &#123; List listByPage(); DatabaseEnum code();&#125; 工厂类可能注意这里用了一个map存储，这里存储的是所有的实例，运行的时候根据配置来调用不同的实现类来完成任务。里面定义了一些方法，并不是所有都需要用到，需要哪个加载Bean,可以通过getBean()来获取.并且从配置文件里实现了两种方式 database.type=mongoDb,mysql或者database.type[0]=mongoDb,database.type[1]=mysql根据喜好来选择吧,这里用的是第二种。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104@Componentpublic class DatabaseFactory implements ApplicationContextAware &#123; //@Value(\"$&#123;database.type&#125;\") private String acceptType; private static AppsType types; private static Map&lt;DatabaseEnum, DatabaseOperationService&gt; beanMap; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; Map&lt;String, DatabaseOperationService&gt; map = applicationContext.getBeansOfType(DatabaseOperationService.class); beanMap = new HashMap&lt;&gt;(); map.forEach((k, v) -&gt; beanMap.put(v.code(), v)); &#125; /** * 根据不同的类型获取bean * * @param code * @param &lt;T&gt; * @return */ public &lt;T extends DatabaseOperationService&gt; T getBean(DatabaseEnum code) &#123; return (T) beanMap.get(code); &#125; /** * 根据配置文件来获取bean * * @param &lt;T&gt; * @return */ public &lt;T extends DatabaseOperationService&gt; T getBean(String code) &#123; return getBean(DatabaseEnum.getAcceptApplicationNameEnum(code)); &#125; /** * 根据单一配置文件来获取bean * * @param &lt;T&gt; * @return */ public &lt;T extends DatabaseOperationService&gt; T getBean() &#123; return getBean(acceptType); &#125; /** * 根据配置文件来获取beans * database.type=mongoDb,mysql... * * @param * @return */ public List getBeans0() &#123; return Arrays.asList(acceptType.split(\",\")) .stream() .distinct() .map(v -&gt; getBean(v)) .collect(Collectors.toList()); &#125; /** * 根据配置文件来获取beans * database.type[0]=mysql * ... * * @param * @return */ public List getBeans() &#123; return types.getType() .stream() .distinct() .map(v -&gt; getBean(v)) .collect(Collectors.toList()); &#125; @EnableConfigurationProperties @ConfigurationProperties(prefix = \"database.type\") public static class AppsType &#123; private List&lt;DatabaseEnum&gt; type; @PostConstruct public void init() &#123; types = this; &#125; public AppsType() &#123; this.type = Lists.newArrayList(); &#125; public List&lt;DatabaseEnum&gt; getType() &#123; return type; &#125; public void setType(List&lt;DatabaseEnum&gt; type) &#123; this.type = type; &#125; &#125;&#125; 对外执行类Executor 这个执行器可以自己定义,这里可以执行两个数据库的内容，然后返回数据.其实这个Executor对外服务的话，假设一个服务不通，根据某种策略，切换另一个服务，这里只是简单演示，并不深究了。 12345678910111213141516@Componentpublic class DatabaseExecutor &#123; @Autowired private DatabaseFactory databaseFactory; /** * 执行列表入口 * * @param apps */ public void execute(List&lt;String&gt; apps) &#123; List&lt;DatabaseOperationService&gt; services = databaseFactory.getBeans(); services.forEach(service -&gt; service.listByPage()); &#125;&#125; 添加配置文件属性配置如下: 123456789database: type[0]: mysql type[1]: mongoDb#或者 database: type: mysql#或者database: type: mysql,mongoDb 调用方调用注入DatabaseExecutor 12345678910@Componentpublic class ApplicationServiceImpl &#123; @Autowired private DatabaseExecutor databaseExecutor; public void listByPage() &#123; databaseExecutor.execute(Lists.newArrayList()); &#125;&#125; 场景比较 第一种方式比较简单，优点简洁明了，不需要多余配置，不同属性增加配置文件里就行了，缺点只能配置一个Configuration，假如遇见多环境，则增加配置文件等会与实际运维等冲突，有些公司配置文件并不由开发人员管理. 第二种方式优点与上面相似，方便快捷, 开发工作量小，可以根据一个配置文件就能确定加载类，而且可以控制加载多个配置 第三种方式其实算是对第二种方式的具体实现，但过程中增加一个DatabaseExecutor,可以多实例运行，扩展性比第一种好，由于不依赖其他，可以手动编写个性化设置.","categories":[{"name":"programmes","slug":"programmes","permalink":"https://chaoscoffee.github.io/categories/programmes/"}],"tags":[{"name":"java","slug":"java","permalink":"https://chaoscoffee.github.io/tags/java/"}],"keywords":[{"name":"programmes","slug":"programmes","permalink":"https://chaoscoffee.github.io/categories/programmes/"}]},{"title":"Markdown语法高亮","slug":"Markdown语法高亮-1","date":"2018-08-28T10:35:06.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/08/28/Markdown语法高亮-1/","link":"","permalink":"https://chaoscoffee.github.io/2018/08/28/Markdown语法高亮-1/","excerpt":"","text":"Markdown语法高亮 Markdown语法高亮 使用方法 语法查询 使用方法使用这组标签```xml 后面跟上标识如：xml，这样markdown就会识别了。 语法查询 名称 关键字 AppleScript applescript ActionScript 3.0 actionscript3, as3 Shell bash, shell ColdFusion coldfusion, cf C cpp, c C# c#, c-sharp, csharp CSS css Delphi delphi, pascal, pas diff&amp;patch diff patch Erlang erl, erlang Groovy groovy Java java JavaFX jfx, javafx JavaScript js, jscript, javascript Perl perl, pl, Perl PHP php text text, plain Python py, python Ruby ruby, rails, ror, rb SASS&amp;SCSS sass, scss Scala scala SQL sql Visual Basic vb, vbnet XML xml, xhtml, xslt, html Objective C objc, obj-c F# f#, f-sharp, fsharp R r, s, splus matlab matlab swift swift GO go, golang","categories":[{"name":"tools","slug":"tools","permalink":"https://chaoscoffee.github.io/categories/tools/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://chaoscoffee.github.io/tags/markdown/"}],"keywords":[{"name":"tools","slug":"tools","permalink":"https://chaoscoffee.github.io/categories/tools/"}]},{"title":"Java Http工具类","slug":"Http-Test-Java","date":"2018-08-23T07:52:44.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/08/23/Http-Test-Java/","link":"","permalink":"https://chaoscoffee.github.io/2018/08/23/Http-Test-Java/","excerpt":"","text":"Java Http工具类 Java Http工具类 引入包概览 Apache Http util maven依赖 代码实例 OkHttp Http util OkHttp 介绍 maven依赖 代码实例 引入包概览123456789101112131415161718import com.alibaba.fastjson.JSONObject;import com.google.common.collect.Maps;import okhttp3.*;import org.apache.http.HttpEntity;import org.apache.http.client.methods.CloseableHttpResponse;import org.apache.http.client.methods.HttpGet;import org.apache.http.client.methods.HttpPost;import org.apache.http.client.utils.URIBuilder;import org.apache.http.entity.ContentType;import org.apache.http.entity.StringEntity;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.HttpClients;import org.apache.http.impl.conn.PoolingHttpClientConnectionManager;import org.apache.http.util.EntityUtils;import java.io.IOException;import java.net.URISyntaxException;import java.util.Map; Apache Http utilmaven依赖12345678910111213141516171819-- maven dependency&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.49&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.6&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpcore&lt;/artifactId&gt; &lt;version&gt;4.4.10&lt;/version&gt;&lt;/dependency&gt; 代码实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101private static final String UTF_8 = \"UTF-8\";private static CloseableHttpClient client;static &#123; PoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager(); cm.setMaxTotal(100); cm.setDefaultMaxPerRoute(20); cm.setDefaultMaxPerRoute(50); client = HttpClients.custom().setConnectionManager(cm).build();&#125;/** * Apache Http Get * * @param url * @param params * @param headers * @return */public Object doGet(String url, Map&lt;String, String&gt; params, Map&lt;String, String&gt; headers) &#123; URIBuilder builder; try &#123; builder = new URIBuilder(url); &#125; catch (URISyntaxException e) &#123; e.printStackTrace(); return null; &#125; params.forEach((k, v) -&gt; builder.addParameter(k, v)); CloseableHttpResponse response = null; try &#123; HttpGet httpGet = new HttpGet(builder.toString()); headers.forEach((k, v) -&gt; httpGet.addHeader(k, v)); client = HttpClients.createDefault(); response = client.execute(httpGet); HttpEntity httpEntity = response.getEntity(); String data = null; if (null != httpEntity) &#123; data = EntityUtils.toString(httpEntity, UTF_8); System.out.println(\"data = \" + data); &#125; return data; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (response != null) &#123; try &#123; response.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return null;&#125;/** * Apache Http Post * * @param url * @param params * @param headers * @return */public String doPost(String url, Map&lt;String, String&gt; params, Map&lt;String, String&gt; headers) &#123; URIBuilder builder = null; try &#123; builder = new URIBuilder(url); &#125; catch (URISyntaxException e) &#123; e.printStackTrace(); &#125; CloseableHttpResponse response = null; try &#123; HttpPost httpPost = new HttpPost(builder.toString()); headers.forEach((k, v) -&gt; httpPost.addHeader(k, v)); JSONObject param = new JSONObject(); param.forEach((k, v) -&gt; param.put(k, v)); StringEntity stringEntity = new StringEntity(param.toJSONString(), ContentType.APPLICATION_JSON); httpPost.setEntity(stringEntity); client = HttpClients.createDefault(); response = client.execute(httpPost); HttpEntity httpEntity = response.getEntity(); String data = null; if (null != httpEntity) &#123; data = EntityUtils.toString(httpEntity, UTF_8); System.out.println(\"data = \" + data); &#125; return data; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (response != null) &#123; try &#123; response.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return null;&#125; OkHttp Http utilOkHttp 介绍 OkHttp是一款优秀的HTTP框架，它支持get请求和post请求，支持基于Http的文件上传和下载，支持加载图片，支持下载文件透明的GZIP压缩，支持响应缓存避免重复的网络请求，支持使用连接池来降低响应延迟问题 maven依赖12345&lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;version&gt;3.9.1&lt;/version&gt;&lt;/dependency&gt; 代码实例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576 /** * okhttp3 Get * * @param url * @param params * @param headers */ public void doOKGet(String url, Map&lt;String, String&gt; params, Map&lt;String, String&gt; headers) &#123; try &#123; OkHttpClient client = new OkHttpClient(); HttpUrl.Builder builder = HttpUrl.parse(url) .newBuilder(); params.forEach((k, v) -&gt; builder.addQueryParameter(k, v)); Request.Builder request = new Request.Builder() .url(builder.build()) .get(); headers.forEach((k, v) -&gt; request.addHeader(k, v)); Response response = client.newCall(request.build()).execute(); System.out.println(\"response = \" + response.isSuccessful()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * okhttp3 Post * * @param url * @param json * @throws IOException */ public void doOKPost(String url, String json, Map&lt;String, String&gt; headers) &#123; OkHttpClient client = new OkHttpClient(); RequestBody body = RequestBody.create(MediaType.parse(\"application/json; charset=utf-8\"), json);//json data Request.Builder request = new Request.Builder() .url(url) .post(body) .addHeader(\"Content-Type\", \"application/json; charset=utf-8\"); headers.forEach((k, v) -&gt; request.addHeader(k, v));//user header data try &#123; Response response = client.newCall(request.build()).execute(); System.out.println(\"response = \" + response.isSuccessful()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; /** * okhttp3 Post * * @param url * @param params * @param headers */ public void doOKPost(String url, Map&lt;String, String&gt; params, Map&lt;String, String&gt; headers) &#123; OkHttpClient client = new OkHttpClient(); FormBody.Builder body = new FormBody.Builder();//form data params.forEach((k, v) -&gt; body.add(k, v)); Request.Builder request = new Request.Builder() .url(url) .post(body.build()); headers.forEach((k, v) -&gt; request.addHeader(k, v));//header data try &#123; Response response = client.newCall(request.build()).execute(); System.out.println(\"response = \" + response.isSuccessful()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; HttpUtils httpUtils = new HttpUtils(); httpUtils.doOKGet(\"http://www.baidu.com\", Maps.newHashMap(), Maps.newHashMap()); &#125;&#125;","categories":[{"name":"programmes","slug":"programmes","permalink":"https://chaoscoffee.github.io/categories/programmes/"}],"tags":[{"name":"java","slug":"java","permalink":"https://chaoscoffee.github.io/tags/java/"}],"keywords":[{"name":"programmes","slug":"programmes","permalink":"https://chaoscoffee.github.io/categories/programmes/"}]},{"title":"Maven-deploy配置方法","slug":"Maven-deploy配置方法","date":"2018-08-20T08:49:39.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/08/20/Maven-deploy配置方法/","link":"","permalink":"https://chaoscoffee.github.io/2018/08/20/Maven-deploy配置方法/","excerpt":"","text":"Maven-deploy配置方法 Maven-deploy配置方法 deploy解释 setting.xml配置 pom.xml配置 deploy解释 deploy顾名思义，就是上传的意思。在本地的pom文件配置好之后，执行deploy命令，可以将maven所打的jar包上传到远程的repository，便于其他开发者和工程共享 setting.xml配置 12345678910&lt;server&gt; &lt;id&gt;releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt;&lt;server&gt; &lt;id&gt;Snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt; pom.xml配置 123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;releases&lt;/id&gt; &lt;name&gt;Internal Releases&lt;/name&gt; &lt;url&gt;http://localhost:8081/nexus/content/repositories/releases&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;Snapshots&lt;/id&gt; &lt;name&gt;Internal Releases&lt;/name&gt; &lt;url&gt;http://localhost:8081/nexus/content/repositories/snapshots&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; 说明: id和url务必写正确，否则无法正确deploy，这个步骤需要验证用户信息，所以与上一步骤server id对应上","categories":[{"name":"tools","slug":"tools","permalink":"https://chaoscoffee.github.io/categories/tools/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://chaoscoffee.github.io/tags/Maven/"}],"keywords":[{"name":"tools","slug":"tools","permalink":"https://chaoscoffee.github.io/categories/tools/"}]},{"title":"GitLab持续集成/部署-Runner核心介绍","slug":"GitLab持续集成-部署-Runner核心介绍","date":"2018-08-17T08:01:03.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/08/17/GitLab持续集成-部署-Runner核心介绍/","link":"","permalink":"https://chaoscoffee.github.io/2018/08/17/GitLab持续集成-部署-Runner核心介绍/","excerpt":"","text":"GitLab持续集成/部署-Runner核心介绍 GitLab持续集成/部署-Runner核心介绍 GitLab-Runner简介 GitLab-Runner架构图 构成组件 Pipeline Stages Jobs 扩展 Shared Runners如何挑选Jobs Example 1 Example 2 参考 GitLab-Runner简介GitLab提供了自动集成、测试，部署的服务，这个动作由GitLab Runner来实现。 GitLab CI 脚本的执行者 GitLab-Runner架构图 构成组件Pipeline 官方解释: pipeline是一组分阶段执行的作业（批处理）。一个阶段中的所有作业都是并行执行的（如果有足够的并发Runners），如果它们都成功，那么pipeline就会进入下一个阶段。如果其中一个作业失败，则不会（通常）执行下一个阶段 一般来说，Pipeline 表示构建任务，里面可以包含多个流程，如安装依赖、运行测试、编译、部署测试服务器、部署生产服务器等流程,任何提交或者 Merge Request 的合并都可以触发 Pipeline StagesStages 表示构建阶段，一次 Pipeline 中定义多个 Stages。 所有 Stages 会按照顺序运行，即当一个 Stage 完成后，下一个 Stage 才会开始 只有当所有 Stages 完成后，该构建任务 (Pipeline) 才会成功 如果任何一个 Stage 失败，那么后面的 Stages 不会执行，该构建任务 (Pipeline) 失败 JobsJobs 表示构建工作，表示某个 Stage 里面执行的工作。一个 Stages 里面定义多个 Jobs， Jobs 会有以下特点：相同 Stage 中的 Jobs 会并行执行相同 Stage 中的 Jobs 都执行成功时，该 Stage 才会成功如果任何一个 Job 失败，那么该 Stage 失败，即该构建任务 (Pipeline) 失败 扩展Shared Runners如何挑选Jobs Shared Runners遵守我们称之为合理使用的进程队列。公平使用算法尝试从当前在共享Runners上运行的作业数量最少的项目中将作业分配给共享的Runners。 Example 1We have following jobs in queue: Job 1 for Project 1 Job 2 for Project 1 Job 3 for Project 1 Job 4 for Project 2 Job 5 for Project 2 Job 6 for Project 3 jobs会按照以下顺序分配: 首先选择Job 1，因为它没有正在运行的作业（即所有项目）的作业编号最低 接下来是Job 4，因为4现在是没有正在运行的作业的项目中的最低Job 编号（项目1正在运行作业） 接下来是Job 6，因为6现在是没有正在运行的Job 的项目中的最低Job 编号（项目1和2有作业正在运行） 接下来是Job 2，因为在运行的Job 数量最少的项目中（每个都有1个），它是最低的Job 编号 接下来是Job 5，因为项目1现在有2个Job 正在运行，而在项目2和3之间，Job 5是剩余的最低Job 编号 最后，我们选择了Job 3 …因为这是唯一剩下的工作 Example 2We have following jobs in queue: Job 1 for Project 1 Job 2 for Project 1 Job 3 for Project 1 Job 4 for Project 2 Job 5 for Project 2 Job 6 for Project 3 jobs会按照以下顺序分配: 首先选择Job 1，因为它没有正在运行的作业（即所有项目）的作业编号最低 我们完成了工作1 接下来是Job 2，因为在完成Job 1后，所有项目都有0个作业再次运行，2是最低可用作业号 接下来是Job 4，因为项目1运行作业时，4是没有作业的项目中的最小数字（Project 2和3） 我们完成了工作4 接下来是Job 5，因为完成了Job 4，Job 2没有再次运行作业 接下来是Job 6，因为Project 3是唯一没有正在运行的作业的项目 最后，我们选择了Job 3 …因为，这是唯一剩下的工作（who says 1 is the loneliest number?） 参考Gitlab-CI/CD 持续集成Introduction to pipelines and jobs Configuring GitLab Runners","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://chaoscoffee.github.io/categories/DevOps/"}],"tags":[{"name":"GitLab-CI","slug":"GitLab-CI","permalink":"https://chaoscoffee.github.io/tags/GitLab-CI/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"https://chaoscoffee.github.io/categories/DevOps/"}]},{"title":"利用Chrome原生工具进行网页长截图","slug":"利用Chrome原生工具进行网页长截图","date":"2018-08-15T03:10:57.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/08/15/利用Chrome原生工具进行网页长截图/","link":"","permalink":"https://chaoscoffee.github.io/2018/08/15/利用Chrome原生工具进行网页长截图/","excerpt":"","text":"Chrome原生工具进行网页长截图 Chrome原生工具进行网页长截图 准备工作 打开调试界面 网页截图 普通网页长截图 1. 打开网页截图工具 2. 输入截图命令 3. 截图 手机版网页长截图 1. 模拟手机设备 2. 手机截图 3. 输入命令 区域截图 1. 区域选中 2. 截图命令 扩展 准备工作在想要截图的网页中，按着以下快捷键 打开调试界面 MacOs ⌘Command + ⌥Option + IWindows 为 F12 网页截图普通网页长截图 1. 打开网页截图工具 MacOs ⌘Command + ⇧Shift + PWindow Ctrl + Shift + P 2. 输入截图命令输入前几个字母就会匹配到,输入以下命令Capture full size screenshot 3. 截图选中所在的命令,敲下回车 Enter 手机版网页长截图1. 模拟手机设备 MacOs ⌘Command + ⇧Shift + MWindows Ctrl + Shift + M 注意: 后面再使用普通的网页截图，仍然使用以上的命令进行切换 2. 手机截图在顶部的工具栏中，你可以选择要模拟的设备和分辨率等设置。 3. 输入命令与 普通网页网页长截图 中1. 2. 3.步骤相同 区域截图 1. 区域选中 MacOs ⌘Command + ⇧Shift + CWindows Ctrl + Shift + C 按照上面命令然后鼠标悬浮在上面,出现蓝色选中区域为止 2. 截图命令先打开截图工具(参见: 普通网页长截图 步骤1),再按着命令 Capture node screenshot 实现区域截图 扩展Capture full size screenshot 命令实现完成网页截图Capture node screenshot 命令实现区域截图Capture screenshot 命令可以截取当前网页的可视部分","categories":[{"name":"tools","slug":"tools","permalink":"https://chaoscoffee.github.io/categories/tools/"}],"tags":[],"keywords":[{"name":"tools","slug":"tools","permalink":"https://chaoscoffee.github.io/categories/tools/"}]},{"title":"Java内存区域","slug":"Java内存区域","date":"2018-08-13T02:08:17.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/08/13/Java内存区域/","link":"","permalink":"https://chaoscoffee.github.io/2018/08/13/Java内存区域/","excerpt":"","text":"运行时数据区域 运行时数据区域 运行时数据区模块图 Java堆 从内存回收角度上看 从内存分配角度看 扩展 异常 方法区 运行时常量池 字面量 符号引用 方法区异常 配置 Java虚拟机栈 栈帧 局部变量表 操作数栈 动态链接 方法出口 栈异常 本地方法栈 程序计数器 直接内存 运行时数据区模块图 Java堆Java虚拟机规范: 所有的对象实例及数组都要在堆上分配 从内存回收角度上看 新生代 Eden From Survivor To Survivor 老年代 从内存分配角度看可划分出多个线程私有的分配缓冲区(`Thread Local Allocation Buffer,TLAB) 扩展 -Xmx 最大堆内存 -Xms 初始化堆内存 -Xmn 新生代内存 -XX:SurvivorRatio=8 定义了新生代的Eden区域一个Survivor区的空间比例是8:1 异常堆中没有内存完成实例分配,并且堆也无法再扩展时候，抛出OutOfMemoryError异常 方法区jdk8之前, JVM用永久代(Permanent Generation)存放方法区 ,方法区逻辑上属于堆的一部分 存储信息包括以下: 类信息 常量 静态变量 即时编译器编译后的代码等数据 运行时常量池Class文件除了有类的版本，字段，方法，接口等描述信息，还有常量池。 常量池用于存放编译器生成的各种字面量和符号引用。除了保存Class文件中描述的符号引用外，翻译出来的直接引用也会存储在运行时常量池中。特性: 动态性，常量不一定只有编译器产生，运行期间也可以将新的常量放入池中 字面量 文本字符串 声明为final的常量值 符号引用 符号引用指的是以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只需使用时能无歧义的定位到目标即可 符号引用包括以下三类常量: 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 Class文件中不会保存各个方法、字段的最终内存布局信息, 字段或方法的符号引用需要经过运行期转换得到真正的内存入口地址，然后被虚拟机使用。当虚拟机运行时，需要从常量池获取对于的符号引用，在类创建或者运行时解析(解析阶段是虚拟机将常量池的符号引用替换为直接引用的过程),翻译到具体的内存地址中。 直接引用 直接指向目标的指针，相对偏移量或者一个可以间接定位到目标的句柄 方法区异常无法满足内存分配需求时候，将抛出OutOfMemoryError异常 配置jdk7-XX:PermSize=10M-XX:MaxPermGen=10M jdk8: Metaspace 元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制，但可以通过以下参数来指定元空间的大小： -XX:MetaspaceSize 初始空间大小-XX:MaxMetaspaceSize 最大空间，默认是没有限制的。 元空间介绍 Java虚拟机栈 生命周期与线程相同 栈帧每个方法执行时创建一个栈帧,用于存储局部变量表，操作数栈，动态链接，方法出口等信息。每一个方法从调用至完成的过程，对应着一个栈帧在虚拟机栈中入栈到出栈的过程。 局部变量表 基本数据类型(boolean,byte,char,short,int,float,long,double) 对象引用(reference类型,它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或者其他与此对象相关的位置) returnAddress类型(指向一条字节码指令的地址) 操作数栈动态链接方法出口栈异常 线程请求的栈深度大于虚拟机所允许的深度，抛出StackOverflowError异常 虚拟机栈动态扩展时无法申请到足够的内存，抛出OutOfMemoryError异常 本地方法栈程序计数器直接内存","categories":[{"name":"JVM","slug":"JVM","permalink":"https://chaoscoffee.github.io/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://chaoscoffee.github.io/tags/JVM/"}],"keywords":[{"name":"JVM","slug":"JVM","permalink":"https://chaoscoffee.github.io/categories/JVM/"}]},{"title":"Ingress-实践","slug":"Ingress-实践","date":"2018-08-10T09:43:08.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/08/10/Ingress-实践/","link":"","permalink":"https://chaoscoffee.github.io/2018/08/10/Ingress-实践/","excerpt":"","text":"Ingress 实践 Ingress 实践 Kubernetes 暴露服务方式 LoadBlancer Service NodePort Service Ingress Ingress 介绍 Ingress 部署 default-backend Ingress Controller 快速部署 创建相关资源 创建ingress-nginx服务 测试 配置TLS SSL访问 创建证书 创建 Secret 快速创建 Secret 重新部署 参考文档 Kubernetes 暴露服务方式到目前为止 Kubernetes 暴露服务的有三种方式，分别为 LoadBlancer Service NodePort Service Ingress LoadBlancer ServiceLoadBlancer Service 是 Kubernetes 结合云平台的组件，如国外 GCE、AWS、国内阿里云等等，使用它向使用的底层云平台申请创建负载均衡器来实现，有局限性，对于使用云平台的集群比较方便。 NodePort ServiceNodePort Service 是通过在节点上暴漏端口，然后通过将端口映射到具体某个服务上来实现服务暴漏，比较直观方便，但是对于集群来说，随着 Service 的不断增加，需要的端口越来越多，很容易出现端口冲突，而且不容易管理。当然对于小规模的集群服务，还是比较不错的。 IngressIngress解决的是新的服务加入后，域名和服务的对应问题，基本上是一个ingress的对象，通过yaml进行创建和更新进行加载。 Ingress使用开源的反向代理负载均衡器来实现对外暴漏服务，比如 Nginx、Apache、Haproxy等。Nginx Ingress 一般有三个组件组成： Nginx 反向代理负载均衡器 Ingress ControllerIngress Controller可以理解为控制器，它通过不断的跟 Kubernetes API 交互，实时获取后端 Service、Pod 等的变化，比如新增、删除等，然后结合 Ingress 定义的规则生成配置，然后动态更新上边的 Nginx 负载均衡器，并刷新使配置生效，来达到服务自动发现的作用，简单来说，Ingress这种变化生成一段Nginx的配置，然后将这个配置通过Kubernetes API写到Nginx的Pod中，然后reload IngressIngress 则是定义规则，通过它定义某个域名的请求过来之后转发到集群中指定的 Service。它可以通过 Yaml 文件定义，可以给一个或多个 Service 定义一个或多个 Ingress 规则。 Ingress 介绍 官网对 Ingress 的定义为管理对外服务到集群内服务之间规则的集合，通俗点讲就是它定义规则来允许进入集群的请求被转发到集群中对应服务上，从来实现服务暴漏。 Ingress 能把集群内 Service 配置成外网能够访问的 URL，流量负载均衡，终止SSL，提供基于域名访问的虚拟主机等等。 Ingress解决的是新的服务加入后，域名和服务的对应问题，基本上是一个ingress的对象，通过yaml进行创建和更新进行加载。可以通过ConfigMap提供的Nginx命令修改参数。 Ingress 部署default-backenddefault-backend生成一个默认的后端，如果遇到解析不到的URL或者发生错误就转发到默认后端dashboard.yaml123456789101112131415161718apiVersion: extensions/v1beta1kind: Ingressmetadata: name: dashboard-weblogic-ingress namespace: kube-systemspec: rules: - host: helloworld.eric http: paths: - path: /console backend: serviceName: helloworldsvc servicePort: 7001 - path: / backend: serviceName: kubernetes-dashboard servicePort: 80 host 指虚拟出来的域名，具体地址(Ingress-controller那台Pod所在的主机的地址)应该加入/etc/hosts中,这样所有去helloworld.eric的请求都会发到nginx path:/console 匹配后面的应用路径 servicePort 主要是定义服务的时候的端口，不是NodePort. path:/ 匹配后面dashboard应用的路径,以前通过访问master节点8080/ui进入dashboard的，但dashboard其实是部署在minion节点中，实际是通过某个路由语句转发过去而已，dashboard真实路径如下: Ingress Controller $ kubectl create -f ingress-nginx/examples/deployment/nginx/nginx-ingress-controller.yaml 快速部署创建相关资源 $ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/mandatory.yaml 创建ingress-nginx服务 $ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/baremetal/service-nodeport.yaml 测试 $ kubectl get svc -o wide -n ingress-nginx$ kubectl create -f hello-world-deployment.yaml 123456789101112131415161718192021222324252627282930apiVersion: apps/v1beta1kind: Deploymentmetadata: name: hello-world-deploymentspec: replicas: 1template: metadata: labels: app: hello-world spec: containers: - image: &quot;gokul93/hello-world:latest&quot; imagePullPolicy: Always name: hello-world-container ports: - containerPort: 8080---apiVersion: v1kind: Servicemetadata: name: hello-world-svcspec: ports: - port: 8080 protocol: TCP targetPort: 8080selector: app: hello-worldtype: NodePort $ kubectl create -f hello-world-ingress.yaml1234567891011121314151617181920apiVersion: extensions/v1beta1kind: Ingressmetadata:annotations: nginx.ingress.kubernetes.io/ssl-redirect: &quot;false&quot;creationTimestamp: 2018-08-03T02:51:13Zgeneration: 2name: hello-world-ingressnamespace: defaultresourceVersion: &quot;3668608&quot;selfLink: /apis/extensions/v1beta1/namespaces/default/ingresses/hello-world-ingressuid: 15b9c53b-96c8-11e8-9920-00505683568fspec:rules:- http: paths: - backend: serviceName: hello-world-svc servicePort: 8080 path: / $ curl k8s-node-ip:32483/hello 配置TLS SSL访问创建证书12345678910111213141516171819202122232425# 生成 CA 自签证书mkdir cert &amp;&amp; cd certopenssl genrsa -out ca-key.pem 2048openssl req -x509 -new -nodes -key ca-key.pem -days 10000 -out ca.pem -subj &quot;/CN=kube-ca&quot;# 编辑 openssl 配置cp /etc/pki/tls/openssl.cnf .vim openssl.cnf# 主要修改如下[req]req_extensions = v3_req # 这行默认注释关着的 把注释删掉# 下面配置是新增的[ v3_req ]basicConstraints = CA:FALSEkeyUsage = nonRepudiation, digitalSignature, keyEnciphermentsubjectAltName = @alt_names[alt_names]DNS.1 = dashboard.mritd.meDNS.2 = kibana.mritd.me# 生成证书openssl genrsa -out ingress-key.pem 2048openssl req -new -key ingress-key.pem -out ingress.csr -subj &quot;/CN=kube-ingress&quot; -config openssl.cnfopenssl x509 -req -in ingress.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out ingress.pem -days 365 -extensions v3_req -extfile openssl.cnf 创建 Secret创建好证书以后，需要将证书内容放到 secret 中，secret 中全部内容需要 base64 编码，然后注意去掉换行符(变成一行) 1234567891011vim ingress-secret.ymlapiVersion: v1data: tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM5akNDQWQ2Z0F3SUJBZ0lKQU5TR2dNNnYvSVd5TUEwR0NTcUdTSWIzRFFFQkJRVUFNQkl4RURBT0JnTlYKQkFNTUIydDFZbVV0WTJFd0hoY05NVGN3TXpBME1USTBPRFF5V2hjTk1UZ3dNekEwTVRJME9EUXlXakFYTVJVdwpFd1lEVlFRRERBeHJkV0psTFdsdVozSmxjM013Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUUM2dkNZRFhGSFpQOHI5Zk5jZXlkV015VVlELzAwQ2xnS0M2WjNpYWZ0QlRDK005TmcrQzloUjhJUE4KWW00cjZOMkw1MmNkcmZvQnBHZXovQVRIT0NJYUhJdlp1K1ZaTzNMZjcxZEVLR09nV21LMTliSVAzaGpSeDZhWQpIeGhEVWNab3ZzYWY1UWJHRnUydEF4L2doMTFMdXpTZWJkT0Y1dUMrWHBhTGVzWWdQUjhFS0cxS0VoRXBLMDFGCmc4MjhUU1g2TXVnVVZmWHZ1OUJRUXExVWw0Q2VMOXhQdVB5T3lMSktzbzNGOEFNUHFlaS9USWpsQVFSdmRLeFYKVUMzMnBtTHRlUFVBb2thNDRPdElmR3BIOTZybmFsMW0rMXp6YkdTemRFSEFaL2k1ZEZDNXJOaUthRmJnL2NBRwppalhlQ01xeGpzT3JLMEM4MDg4a0tjenJZK0JmQWdNQkFBR2pTakJJTUM0R0ExVWRFUVFuTUNXQ0VtUmhjMmhpCmIyRnlaQzV0Y21sMFpDNXRaWUlQYTJsaVlXNWhMbTF5YVhSa0xtMWxNQWtHQTFVZEV3UUNNQUF3Q3dZRFZSMFAKQkFRREFnWGdNQTBHQ1NxR1NJYjNEUUVCQlFVQUE0SUJBUUNFN1ByRzh6MytyaGJESC8yNGJOeW5OUUNyYVM4NwphODJUUDNxMmsxUUJ1T0doS1pwR1N3SVRhWjNUY0pKMkQ2ZlRxbWJDUzlVeDF2ckYxMWhGTWg4MU9GMkF2MU4vCm5hSU12YlY5cVhYNG16eGNROHNjakVHZ285bnlDSVpuTFM5K2NXejhrOWQ1UHVaejE1TXg4T3g3OWJWVFpkZ0sKaEhCMGJ5UGgvdG9hMkNidnBmWUR4djRBdHlrSVRhSlFzekhnWHZnNXdwSjlySzlxZHd1RHA5T3JTNk03dmNOaQpseWxDTk52T3dNQ0h3emlyc01nQ1FRcVRVamtuNllLWmVsZVY0Mk1yazREVTlVWFFjZ2dEb1FKZEM0aWNwN0sxCkRPTDJURjFVUGN0ODFpNWt4NGYwcUw1aE1sNGhtK1BZRyt2MGIrMjZjOVlud3ROd24xdmMyZVZHCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K tls.key: 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kind: Secretmetadata: name: ingress-secret namespace: kube-systemtype: Opaque kubectl create -f ingress-secret.yml 快速创建 Secret kubectl create secret tls ingress-secret –key cert/ingress-key.pem –cert cert/ingress.pem 重新部署123456789101112131415161718192021222324apiVersion: extensions/v1beta1kind: Ingressmetadata: name: dashboard-kibana-ingress namespace: kube-systemspec: tls: - hosts: - dashboard.mritd.me - kibana.mritd.me secretName: ingress-secret rules: - host: dashboard.mritd.me http: paths: - backend: serviceName: kubernetes-dashboard servicePort: 80 - host: kibana.mritd.me http: paths: - backend: serviceName: kibana-logging servicePort: 5601 注意:一个 Ingress 只能使用一个 secret(secretName 段只能有一个)，也就是说只能用一个证书，更直白的说就是如果你在一个 Ingress 中配置了多个域名，那么使用 TLS 的话必须保证证书支持该 Ingress 下所有域名；并且这个 secretName 一定要放在上面域名列表最后位置，否则会报错 did not find expected key无法创建；同时上面的 hosts 段下域名必须跟下面的 rules 中完全匹配 更需要注意一点：Kubernetes Ingress 默认情况下，当你不配置证书时，会默认给你一个 TLS 证书的，也就是说你 Ingress 中配置错了，比如写了2个 secretName、或者 hosts 段中缺了某个域名，那么对于写了多个 secretName 的情况，所有域名全会走默认证书；对于 hosts 缺了某个域名的情况，缺失的域名将会走默认证书，部署时一定要验证一下证书，不能 “有了就行”；更新 Ingress 证书可能需要等一段时间才会生效 参考文档Kubernetes Nginx Ingress 教程","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://chaoscoffee.github.io/categories/kubernetes/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://chaoscoffee.github.io/tags/kubernetes/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://chaoscoffee.github.io/categories/kubernetes/"}]},{"title":"Kubernetes-搭建本地环境","slug":"Kubernetes-搭建本地环境","date":"2018-08-07T05:27:45.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/08/07/Kubernetes-搭建本地环境/","link":"","permalink":"https://chaoscoffee.github.io/2018/08/07/Kubernetes-搭建本地环境/","excerpt":"","text":"kubernetes 搭建本地环境 kubernetes 搭建本地环境 Chocolatey安装 更换镜像 安装virtualbox 添加所需要的库 更新yum缓存 安装virtualbox 安装 DKMS、更新内核 开启虚拟机虚化 安装 docker 安装kubectl 修改kubernetes.repo 安装kubectl、kubelet、kubeadm(所有节点) Minikube 下载安装 配置环境变量 启动 停止 删除 访问 Kubernetes部署 拉取镜像 发布服务 命令行模式 声明式模式(推荐) 查看Pod 查看service 查看日志 更新配置 销毁服务 客户端访问 查看master 查看config 问题 如何关闭防火墙？ minikube镜像下载不了？ 参考文献 Chocolatey安装安装 Chocolatey管理员身份运行cmd.exe 1@&quot;%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe&quot; -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command &quot;iex ((New-Object System.Net.WebClient).DownloadString(&apos;https://chocolatey.org/install.ps1&apos;))&quot; &amp;&amp; SET &quot;PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin&quot; choco choco upgrade chocolatey choco install kubernetes-cli 更换镜像[防火墙] $ cd /etc/sysconfig/network-scripts$ service network restart [更换yum] $ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo $ yum makecache $ yum repolist $ yum repoinfo 安装virtualbox添加所需要的库 $ yum install wget$ cd /etc/yum.repos.d/$ wget http://download.virtualbox.org/virtualbox/rpm/rhel/virtualbox.repo virtualbox.repo内容如下: 1234567[virtualbox]name=Oracle Linux / RHEL / CentOS-$releasever / $basearch - VirtualBoxbaseurl=http://download.virtualbox.org/virtualbox/rpm/el/$releasever/$basearchenabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://www.virtualbox.org/download/oracle_vbox.asc 更新yum缓存 $ yum clean all $ yum makecache 安装virtualbox $ yum install VirtualBox-5.1 安装 DKMS、更新内核 $ yum -y install gcc make glibc kernel-headers kernel-devel dkms$ yum -y update kernel$ reboot 开启虚拟机虚化需要在BIOS里开启虚拟机虚化 安装 docker $ yum search docker$ yum install -y docker$ systemctl start docker 安装kubectl修改kubernetes.repo12345[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0 安装kubectl、kubelet、kubeadm(所有节点) kubelet: 运行在cluster所有节点上,负责启动POD和容器 kubeadm: 用于初始化cluster kubectl: kubectl是kubenetes命令行工具，通过kubectl可以部署和管理应用，查看各种资源，创建，删除和更新组件 $ yum install -y kubectl$ yum install -y kubelet$ yum install -y kubeadm MinikubeMinikube 是一个允许开发人员在本地使用和运行 Kubernetes 集群的工具 下载安装下载minikube[Linux] $ curl -Lo minikube http://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/releases/v0.28.0/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/ [Windows] $ choco install minikube 配置环境变量MINIKUBE_HOME=D:\\kuberbnetesMINIKUBE_WANTREPORTERRORPROMPT=falseMINIKUBE_WANTUPDATENOTIFICATION=false 启动 $ minikube start –registry-mirror=https://registry.docker-cn.com–vm-driver=none //不用虚拟机 $ minikube start –vm-driver=virtualbox –registry-mirror=https://registry.docker-cn.com $ minikube start –vm-driver=hyperv –registry-mirror=https://registry.docker-cn.com Windowswindows10可以使用自带hyper-v参考启动配置: 12345$ minikube start --vm-driver=hyperv --hyperv-virtual-switch=minikube-Switch --registry-mirror=https://registry.docker-cn.com$ minikube start --vm-driver=&quot;hyperv&quot; --memory=4096 --cpus=4 --hyperv-virtual-switch=&quot;minikube-Switch&quot; --v=7 --alsologtostderr$ minikube start --vm-driver=&quot;hyperv&quot; --hyperv-virtual-switch=&quot;minikube-Switch&quot; --v=7 --alsologtostderr 作者配置(通过测试) $ minikube start –vm-driver “hyperv” –hyperv-virtual-switch “minikube-Switch” –v 9999 –alsologtostderr 停止 $ minikube stop 删除启动失败需要rm -rf 删除 ./minikube下的内容,再使用 $ minikube delete 最后重新执行启动命令 访问 $ minikube dashboard$ minikube service hello-node Kubernetes部署拉取镜像 $ docker pull chenliujin/defaultbackend:1.4$ docker tag chenliujin/defaultbackend:1.4 gcr.io/google_containers/defaultbackend:1.4 发布服务这里用NodePort对外提供服务 命令行模式 $kubectl run hello-minikube –image=k8s.gcr.io/echoserver:1.4 –port=8081$kubectl expose deployment hello-minikube –type=NodePort $ kubectl run –image=nginx nginx-app –port=80$ kubectl expose deployment nginx-app –port=80 –name=nginx-http –type=NodePort 设置镜像 $ kubectl set image deployment/hello-node hello-node=hello-node:v2 声明式模式(推荐)推荐使用 $ kubectl create -f nginx-rc.yaml 123456789101112131415161718apiVersion: v1 kind: ReplicationControllermetadata:name: nginx-rcspec:replicas: 2selector:app: nginxtemplate:metadata:labels:app: nginxspec:containers:- name: nginximage: nginxports:- containerPort: 80 $ kubectl create -f nginx-service.yaml 123456789101112apiVersion: v1 kind: Servicemetadata:name: nginx-servicespec:ClusterIP: Noneports:- port: 80targetPort: 80protocol: TCPselector:app: nginx 查看Pod查看默认的pod $ kubectl get pods 查看所有namespace的pod数据 $ kubectl get pods –all-namespaces -o wide 请求部署的service $ curl $(minikube service hello-minikube –url) 查看service $ kubectl get services$ kubectl get service –all-namespaces 查看日志$ minikube logs 更新配置 $ kubectl replace -f rc-nginx.yaml 销毁服务 $ kubectl delete service nginx-service$ kubectl delete deployment nginx-pod$ kubectl delete rc nginx-service 客户端访问 $ curl ‘192.168.64.2:30716’$ minikube service nginx-http访问部署service$ minikube service hello-node 查看master $ kubectl cluster-info 查看config $ kubectl config view 问题如何关闭防火墙？关闭防火墙 $ systemctl stop firewalld //临时关闭$ systemctl disable firewalld //禁止开机启动$ Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.$ Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service. 访问: http://127.0.0.1:8001/ui minikube镜像下载不了？下载不了如何解决说明：由于GFW的原因下载不下来的，都可以到时速云去下载相应的镜像（只要把grc.io换成index.tenxcloud.com就可以了。或者用私用镜像仓库，tag之后上传到之后看到的镜像是自己私有镜像仓库的。 1$ sudo docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1 &amp;&amp; sudo docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1 k8s.gcr.io/pause-amd64:3.1 &amp;&amp; sudo /usr/bin/kubeadm init --config /var/lib/kubeadm.yaml --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests --ignore-preflight-errors=DirAvailable--data-minikube --ignore-preflight-errors=Port-10250 --ignore-preflight-errors=FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml --ignore-preflight-errors=FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml --ignore-preflight-errors=FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml --ignore-preflight-errors=FileAvailable--etc-kubernetes-manifests-etcd.yaml --ignore-preflight-errors=Swap --ignore-preflight-errors=CRI 123$ minikube ssh$ docker pull registry.cn-hangzhou.aliyuncs.com/google-containers/pause-amd64:3.0$ docker tag registry.cn-hangzhou.aliyuncs.com/google-containers/pause-amd64:3.0 gcr.io/google_containers/pause-amd64:3.0 参考文献[参考] Kubernetes本地实验环境通过Minikube快速搭建一个本地的Kubernetes单节点环境","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://chaoscoffee.github.io/categories/kubernetes/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://chaoscoffee.github.io/tags/kubernetes/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://chaoscoffee.github.io/categories/kubernetes/"}]},{"title":"Kubernetes-介绍","slug":"Kubernetes-介绍","date":"2018-08-07T03:09:04.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/08/07/Kubernetes-介绍/","link":"","permalink":"https://chaoscoffee.github.io/2018/08/07/Kubernetes-介绍/","excerpt":"","text":"Kubernetes 介绍 Kubernetes 介绍 Kubernetes架构 架构图 节点 分层架构 使用Kubernetes能做什么？ Kubernetes不是什么？ Kubernetes架构架构图Kubernetes集群包含有节点代理kubelet和Master组件(APIs, scheduler, etc)，一切都基于分布式的存储系统。下面这张图是Kubernetes的架构图。 节点在这张系统架构图中，我们把服务分为运行在工作节点上的服务和组成集群级别控制板的服务。 Kubernetes节点有运行应用容器必备的服务，而这些都是受Master的控制。 每次个节点上当然都要运行Docker。Docker来负责所有具体的映像下载和容器运行。 Kubernetes主要由以下几个核心组件组成： etcd保存了整个集群的状态； apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制； controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等； scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上； kubelet负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理； Container runtime负责镜像管理以及Pod和容器的真正运行（CRI）； kube-proxy负责为Service提供cluster内部的服务发现和负载均衡； 除了核心组件，还有一些推荐的Add-ons： kube-dns负责为整个集群提供DNS服务 Ingress Controller为服务提供外网入口 Heapster提供资源监控 Dashboard提供GUI Federation提供跨可用区的集群 Fluentd-elasticsearch提供集群日志采集、存储与查询 分层架构Kubernetes设计理念和功能其实就是一个类似Linux的分层架构，如下图所示 核心层：Kubernetes最核心的功能，对外提供API构建高层的应用，对内提供插件式应用执行环境 应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS解析等） 管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态Provision等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy等） 接口层：kubectl命令行工具、客户端SDK以及集群联邦 生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴 Kubernetes外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS应用、ChatOps等 Kubernetes内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等 使用Kubernetes能做什么？可以在物理或虚拟机的Kubernetes集群上运行容器化应用，Kubernetes能提供一个以“容器为中心的基础架构”，满足在生产环境中运行应用的一些常见需求，如： 多个进程（作为容器运行）协同工作。（Pod） 存储系统挂载 Distributing secrets 应用健康检测 应用实例的复制 Pod自动伸缩/扩展 Naming and discovering 负载均衡 滚动更新 资源监控 日志访问 调试应用程序 提供认证和授权 Kubernetes不是什么？Kubernetes并不是传统的PaaS（平台即服务）系统。 Kubernetes不限制支持应用的类型，不限制应用框架。限制受支持的语言runtimes (例如, Java, Python, Ruby)，满足12-factor applications 。不区分 “apps” 或者“services”。 Kubernetes支持不同负载应用，包括有状态、无状态、数据处理类型的应用。只要这个应用可以在容器里运行，那么就能很好的运行在Kubernetes上。 Kubernetes不提供中间件（如message buses）、数据处理框架（如Spark）、数据库(如Mysql)或者集群存储系统(如Ceph)作为内置服务。但这些应用都可以运行在Kubernetes上面。 Kubernetes不部署源码不编译应用。持续集成的 (CI)工作流方面，不同的用户有不同的需求和偏好的区域，因此，我们提供分层的 CI工作流，但并不定义它应该如何工作。 Kubernetes允许用户选择自己的日志、监控和报警系统。 Kubernetes不提供或授权一个全面的应用程序配置 语言/系统（例如，jsonnet）。 Kubernetes不提供任何机器配置、维护、管理或者自修复系统。 另一方面，大量的Paas系统都可以运行在Kubernetes上，比如Openshift、Deis、Gondor。可以构建自己的Paas平台，与自己选择的CI系统集成。 由于Kubernetes运行在应用级别而不是硬件级，因此提供了普通的Paas平台提供的一些通用功能，比如部署，扩展，负载均衡，日志，监控等。这些默认功能是可选的。 另外，Kubernetes不仅仅是一个“编排系统”；它消除了编排的需要。“编排”的定义是指执行一个预定的工作流：先执行A，之B，然C。相反，Kubernetes由一组独立的可组合控制进程组成。怎么样从A到C并不重要，达到目的就好。当然集中控制也是必不可少，方法更像排舞的过程。这使得系统更加易用、强大、弹性和可扩展。","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://chaoscoffee.github.io/categories/kubernetes/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://chaoscoffee.github.io/tags/kubernetes/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://chaoscoffee.github.io/categories/kubernetes/"}]},{"title":"Markdown语法","slug":"Markdown语法","date":"2018-07-27T03:34:20.000Z","updated":"2018-09-10T10:31:35.600Z","comments":false,"path":"2018/07/27/Markdown语法/","link":"","permalink":"https://chaoscoffee.github.io/2018/07/27/Markdown语法/","excerpt":"","text":"欢迎使用Markdown编辑器写博客本Markdown编辑器使用StackEdit修改而来，用它写博客，将会带来全新的体验哦： Markdown和扩展Markdown简洁的语法 代码块高亮 图片链接和图片上传 LaTex数学公式 UML序列图和流程图 离线写博客 导入导出Markdown文件 丰富的快捷键 快捷键 加粗 Ctrl + B 斜体 Ctrl + I 引用 Ctrl + Q 插入链接 Ctrl + L 插入代码 Ctrl + K 插入图片 Ctrl + G 提升标题 Ctrl + H 有序列表 Ctrl + O 无序列表 Ctrl + U 横线 Ctrl + R 撤销 Ctrl + Z 重做 Ctrl + Y Markdown及扩展 Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面。 —— [ 维基百科 ] 使用简单的符号标识不同的标题，将某些文字标记为粗体或者斜体，创建一个链接等，详细语法参考帮助？。 本编辑器支持 Markdown Extra , 扩展了很多好用的功能。具体请参考Github. 表格Markdown Extra 表格语法： 项目 价格 Computer $1600 Phone $12 Pipe $1 可以使用冒号来定义对齐方式： 项目 价格 数量 Computer 1600 元 5 Phone 12 元 12 Pipe 1 元 234 定义列表Markdown Extra 定义列表语法：项目１项目２: 定义 A: 定义 B 项目３: 定义 C : 定义 D &gt; 定义D内容 代码块代码块语法遵循标准markdown代码，例如：12345678910@requires_authorizationdef somefunc(param1='', param2=0): '''A docstring''' if param1 &gt; param2: # interesting print 'Greater' return (param2 - param1 + 1) or Noneclass SomeClass: pass&gt;&gt;&gt; message = '''interpreter... prompt''' 脚注生成一个脚注[^footnote]. [^footnote]: 这里是 脚注 的 内容. 目录用 [TOC]来生成目录： [TOC] 数学公式使用MathJax渲染LaTex 数学公式，详见math.stackexchange.com. 行内公式，数学公式为：$\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$。 块级公式： $$ x = \\dfrac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$ 更多LaTex语法请参考 这儿. UML 图:可以渲染序列图： 123张三-&gt;李四: 嘿，小四儿, 写博客了没?Note right of 李四: 李四愣了一下，说：李四--&gt;张三: 忙得吐血，哪有时间写。 或者流程图： 12345678st=&gt;start: 开始e=&gt;end: 结束op=&gt;operation: 我的操作cond=&gt;condition: 确认？st-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 关于 序列图 语法，参考 这儿, 关于 流程图 语法，参考 这儿. 离线写博客即使用户在没有网络的情况下，也可以通过本编辑器离线写博客（直接在曾经使用过的浏览器中输入write.blog.csdn.net/mdeditor即可。Markdown编辑器使用浏览器离线存储将内容保存在本地。 用户写博客的过程中，内容实时保存在浏览器缓存中，在用户关闭浏览器或者其它异常情况下，内容不会丢失。用户再次打开浏览器时，会显示上次用户正在编辑的没有发表的内容。 博客发表后，本地缓存将被删除。 用户可以选择 把正在写的博客保存到服务器草稿箱，即使换浏览器或者清除缓存，内容也不会丢失。 注意：虽然浏览器存储大部分时候都比较可靠，但为了您的数据安全，在联网后，请务必及时发表或者保存到服务器草稿箱。 浏览器兼容 目前，本编辑器对Chrome浏览器支持最为完整。建议大家使用较新版本的Chrome。 IE９以下不支持 IE９，１０，１１存在以下问题 不支持离线功能 IE9不支持文件导入导出 IE10不支持拖拽文件导入","categories":[{"name":"tools","slug":"tools","permalink":"https://chaoscoffee.github.io/categories/tools/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://chaoscoffee.github.io/tags/markdown/"}],"keywords":[{"name":"tools","slug":"tools","permalink":"https://chaoscoffee.github.io/categories/tools/"}]}]}